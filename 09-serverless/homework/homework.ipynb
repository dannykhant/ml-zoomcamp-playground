{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3075004a-83e3-48ef-9879-600eb32d858a",
   "metadata": {},
   "source": [
    "Q1: What's the name of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a486e5-517c-4fc2-a1ca-9a3c3182a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: input, Output: output\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    \"hair_classifier_v1.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "print(f\"Input: {input_name}, Output: {output_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430d498-8952-4907-9698-735078e5608c",
   "metadata": {},
   "source": [
    "Q2: Based on the previous homework, what should be the target size for the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20222821-40bc-417e-b0a7-0bdaa6a7357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST) # type: ignore\n",
    "    return img\n",
    "\n",
    "img = download_image(\"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\")\n",
    "X = prepare_image(img, target_size=(200, 200))\n",
    "print(X.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b1e46-83bf-4765-bfda-fc65b3662d41",
   "metadata": {},
   "source": [
    "Q3: After the pre-processing, what's the value in the first pixel, the R channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f269cc12-9c39-4a76-a267-67906f821e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pytorch_preprocessing(X):\n",
    "  X = X / 255.\n",
    "\n",
    "  mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
    "  std = np.array([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
    "\n",
    "  X = X.transpose(0, 3, 1, 2)\n",
    "  X = (X - mean) / std\n",
    "\n",
    "  return X.astype(np.float32)\n",
    "\n",
    "def preprocess(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    small = img.resize(target_size, Image.NEAREST) # type: ignore\n",
    "    x = np.array(small, dtype='float32')\n",
    "    batch = np.expand_dims(x, axis=0)\n",
    "\n",
    "    return pytorch_preprocessing(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c72b43-eabd-44a1-8965-66aff3ea191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0732939  -1.0047948  -1.0390444  -1.1075435  -1.0904187  -1.0219196\n",
      " -1.0390444  -1.1246682  -1.0219196  -1.0561692  -1.0390444  -1.0047948\n",
      " -1.0904187  -1.0390444  -1.0561692  -1.1246682  -1.1589177  -1.1589177\n",
      " -1.1931672  -1.2274168  -1.2445415  -1.3301653  -1.2445415  -1.2274168\n",
      " -1.2959157  -1.2274168  -1.2445415  -1.210292   -1.141793   -1.1246682\n",
      " -1.0732939  -1.0732939  -0.9876701  -0.9534206  -0.93629587 -0.86779684\n",
      " -0.93629587 -0.6965493  -0.7992978  -0.6280503  -0.5253018  -0.5253018\n",
      " -0.42255327 -0.30268002 -0.19993149 -0.08005822 -0.18280673 -0.08005822\n",
      "  0.22818747  0.29668647  0.467934    0.8618033   1.3070469   1.5296687\n",
      "  1.8379142   1.992037    1.9064132   1.9406627   1.992037    2.0262866\n",
      "  2.14616     2.060536    1.7694153   1.5467935   1.5639182   1.8892885\n",
      "  2.0434113   2.1119103   2.0434113   2.0434113   1.9749123   1.8892885\n",
      "  1.5639182   0.74193007  0.34806073  0.05693981  0.51930827  0.19393796\n",
      "  0.8275538   1.4611697   1.5296687   1.2385479   0.5878073   0.5706825\n",
      "  1.0330509   1.0501755   1.3926706   1.8721638   1.2556727   0.89605284\n",
      "  0.9303023   0.74193007  1.0673003   1.2899221   0.604932    0.74193007\n",
      "  0.81042904  0.7076805   1.1015499   1.2899221   1.2042984   0.91317755\n",
      "  1.2385479   0.87892807  1.2899221   1.3070469   0.74193007  0.7076805\n",
      "  0.29668647  1.4097954   1.7865399   1.444045    1.6666667   1.2214231\n",
      "  1.1700488   0.9816766   1.1015499   0.7076805   0.27956173  0.33093598\n",
      "  0.74193007  1.1186746   1.4269202   1.855039    1.7694153   1.7009162\n",
      "  1.6837914   1.8036647   1.8892885   2.0091617   1.992037    2.0776608\n",
      "  2.197534    2.1804092   2.1632845   2.2146587   2.197534    2.1804092\n",
      "  2.0434113   2.129035    2.1804092   2.197534    2.1804092   2.1804092\n",
      "  2.1119103   2.1119103   2.1119103   2.0091617   1.9064132   1.8379142\n",
      "  1.6152924   1.6152924   1.4782944   1.4611697   1.3070469   1.2214231\n",
      "  1.1529241   1.2556727   1.2899221   1.1186746   1.0159261   0.99880135\n",
      "  1.0501755   0.9645518   0.9816766   1.0159261   0.89605284  0.7933043\n",
      "  0.77617955  0.65630627  0.65630627  0.6220568   0.5021835   0.34806073\n",
      "  0.467934    0.39943498  0.41655976  0.24531221  0.19393796  0.07406469\n",
      "  0.10831419  0.03981505  0.05693981  0.09118944 -0.09718297 -0.02868396\n",
      " -0.14855723 -0.31980476 -0.31980476 -0.49105227 -0.5253018  -0.5424265\n",
      " -0.61092556 -0.6794246  -0.74792355 -0.8849216  -0.97054535 -1.0732939\n",
      " -1.0732939  -1.210292  ]\n"
     ]
    }
   ],
   "source": [
    "img = download_image(\"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\")\n",
    "X = preprocess(img, target_size=(200, 200))\n",
    "print(X[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ac95c-aac0-432d-827f-62274372adf6",
   "metadata": {},
   "source": [
    "Q4: What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c705fbbd-1613-4da2-8ed4-5a5d27ff7743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09156627207994461"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = session.run([output_name], {input_name: X})\n",
    "preds = result[0][0].tolist()\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61191210-ddea-42d6-9c38-dd1cddcc0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    \"hair_classifier_v1.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def pytorch_preprocessing(X):\n",
    "  X = X / 255.\n",
    "\n",
    "  mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
    "  std = np.array([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
    "\n",
    "  X = X.transpose(0, 3, 1, 2)\n",
    "  X = (X - mean) / std\n",
    "\n",
    "  return X.astype(np.float32)\n",
    "\n",
    "\n",
    "def preprocess(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    small = img.resize(target_size, Image.NEAREST) # type: ignore\n",
    "    x = np.array(small, dtype='float32')\n",
    "    batch = np.expand_dims(x, axis=0)\n",
    "\n",
    "    return pytorch_preprocessing(batch)\n",
    "\n",
    "\n",
    "def predict(url):\n",
    "    img = download_image(url)\n",
    "    X = preprocess(img, target_size=(200, 200))\n",
    "    \n",
    "    result = session.run([output_name], {input_name: X})\n",
    "    preds = result[0][0].tolist()\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    url = event[\"url\"]\n",
    "    result = predict(url)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec9a560-0f68-47ed-b466-82eb5956b822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09156627207994461]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada798e0-e8c4-4788-b88a-321a7560b157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp-playground",
   "language": "python",
   "name": "ml-zoomcamp-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
